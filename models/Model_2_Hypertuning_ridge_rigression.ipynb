{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import linear_model\n",
    "from sklearn import  tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "############################################################################################\n",
    "from DataPreprocessing import DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading The Data of clusters.\n",
    "cluster1=pd.read_csv('Data/cluster_1.csv')\n",
    "cluster2=pd.read_csv('Data/cluster_2.csv')\n",
    "cluster3=pd.read_csv('Data/cluster_3.csv')\n",
    "cluster4=pd.read_csv('Data/cluster_4.csv')\n",
    "cluster5=pd.read_csv('Data/cluster_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DP1 = DataPreprocessing()\n",
    "time_series_df1 = cluster1[[\"Rainfall\"]]\n",
    "\n",
    "DP2 = DataPreprocessing()\n",
    "time_series_df2 = cluster2[[\"Rainfall\"]]\n",
    "\n",
    "DP3 = DataPreprocessing()\n",
    "time_series_df3 = cluster3[[\"Rainfall\"]]\n",
    "\n",
    "DP4 = DataPreprocessing()\n",
    "time_series_df4 = cluster4[[\"Rainfall\"]]\n",
    "\n",
    "DP5 = DataPreprocessing()\n",
    "time_series_df5 = cluster5[[\"Rainfall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10,30,10):\n",
    "    \n",
    "X1, y1 = DP1.create_dataset_in_time_series_form(entire_dataframe=time_series_df1[[\"Rainfall\"]], time_series_column=\"Rainfall\", time_horizon=40)\n",
    "#     model1=linear_model.Ridge()\n",
    "#     random_search1=RandomizedSearchCV(estimator = model1, param_distributions = random_grid1, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = 8)\n",
    "#     random_search1.fit(X1,y1)\n",
    "#     all_best_params.append(random_search1.best_params_)\n",
    "\n",
    "X2, y2 = DP2.create_dataset_in_time_series_form(entire_dataframe=time_series_df2[[\"Rainfall\"]], time_series_column=\"Rainfall\", time_horizon=40)\n",
    "\n",
    "X3, y3 = DP3.create_dataset_in_time_series_form(entire_dataframe=time_series_df3[[\"Rainfall\"]], time_series_column=\"Rainfall\", time_horizon=40)\n",
    "\n",
    "X4, y4 = DP4.create_dataset_in_time_series_form(entire_dataframe=time_series_df4[[\"Rainfall\"]], time_series_column=\"Rainfall\", time_horizon=40)\n",
    "\n",
    "X5, y5 = DP5.create_dataset_in_time_series_form(entire_dataframe=time_series_df5[[\"Rainfall\"]], time_series_column=\"Rainfall\", time_horizon=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=[i for i in np.linspace(start = 0, stop = 1, num = 10000)]\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid1={'alpha':alpha}\n",
    "\n",
    "random_grid2 = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=linear_model.Ridge()\n",
    "model2=linear_model.Ridge()\n",
    "model3=linear_model.Ridge()\n",
    "model4=linear_model.Ridge()\n",
    "model5=linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6=tree.DecisionTreeRegressor()\n",
    "model7=tree.DecisionTreeRegressor()\n",
    "model8=tree.DecisionTreeRegressor()\n",
    "model9=tree.DecisionTreeRegressor()\n",
    "model10=tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search1=RandomizedSearchCV(estimator = model1, param_distributions = random_grid1, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search2=RandomizedSearchCV(estimator = model2, param_distributions = random_grid1, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search3=RandomizedSearchCV(estimator = model3, param_distributions = random_grid1, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search4=RandomizedSearchCV(estimator = model4, param_distributions = random_grid1, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search5=RandomizedSearchCV(estimator = model5, param_distributions = random_grid1, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_search6=RandomizedSearchCV(estimator = model6, param_distributions = random_grid2, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search7=RandomizedSearchCV(estimator = model7, param_distributions = random_grid2, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search8=RandomizedSearchCV(estimator = model8, param_distributions = random_grid2, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search9=RandomizedSearchCV(estimator = model9, param_distributions = random_grid2, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "random_search10=RandomizedSearchCV(estimator= model10, param_distributions =random_grid2, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   20.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 276 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 106 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  88 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  70 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 276 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=8,\n",
       "          param_distributions={'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search1.fit(X1,y1)\n",
    "random_search2.fit(X2,y2)\n",
    "random_search3.fit(X3,y3)\n",
    "random_search4.fit(X4,y4)\n",
    "random_search5.fit(X5,y5)\n",
    "\n",
    "\n",
    "\n",
    "random_search6.fit(X1,y1)\n",
    "random_search7.fit(X2,y2)\n",
    "random_search8.fit(X3,y3)\n",
    "random_search9.fit(X4,y4)\n",
    "random_search10.fit(X5,y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_search1:  {'alpha': 0.999899989999}\n",
      "random_search2:  {'alpha': 0.999899989999}\n",
      "random_search3:  {'alpha': 0.999899989999}\n",
      "random_search4:  {'alpha': 0.999899989999}\n",
      "random_search5:  {'alpha': 0.999899989999}\n",
      "random_search6:  {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "random_search7:  {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "random_search8:  {'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "random_search9:  {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "random_search10:  {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"random_search1: \",random_search1.best_params_)\n",
    "print(\"random_search2: \",random_search2.best_params_)\n",
    "print(\"random_search3: \",random_search3.best_params_)\n",
    "print(\"random_search4: \",random_search4.best_params_)\n",
    "print(\"random_search5: \",random_search5.best_params_)\n",
    "\n",
    "\n",
    "print(\"random_search6: \",random_search6.best_params_)\n",
    "print(\"random_search7: \",random_search7.best_params_)\n",
    "print(\"random_search8: \",random_search8.best_params_)\n",
    "print(\"random_search9: \",random_search9.best_params_)\n",
    "print(\"random_search10: \",random_search10.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python|StatisticalML",
   "language": "python",
   "name": "statisticalml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
